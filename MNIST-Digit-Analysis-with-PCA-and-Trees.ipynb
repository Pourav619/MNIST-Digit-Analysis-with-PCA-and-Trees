{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "(784, 10)\n",
      "(18623, 10)\n",
      "[-1139.38939686+0.j  -587.9349331 +0.j  -584.30307529+0.j\n",
      "   208.50597448+0.j  -335.67509036+0.j   138.61672253+0.j\n",
      "   244.73422311+0.j  -111.01412832+0.j   -52.94452131+0.j\n",
      "     8.25235943+0.j]\n",
      "(18623,)\n",
      "Dimensions: (18623, 10)\n",
      "(3147, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_data = np.load('mnist.npz')\n",
    "\n",
    "# Extract training data and labels\n",
    "X_train = mnist_data['x_train']\n",
    "y_train = mnist_data['y_train']\n",
    "x_test = mnist_data['x_test']\n",
    "y_test = mnist_data['y_test']\n",
    "\n",
    "# Storing the indexes\n",
    "indices = (y_train == 0) | (y_train == 1) | (y_train == 2)\n",
    "\n",
    "X = X_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "indices1 = (y_test == 0) | (y_test == 1) | (y_test == 2)\n",
    "\n",
    "x_test = x_test[indices1]\n",
    "y_test = y_test[indices1]\n",
    "\n",
    "# Reshape and flatening the data to 2D\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "x_test= x_test.reshape(x_test.shape[0], -1)\n",
    "# print(X_012.shape)\n",
    "\n",
    "# Compute mean of the dataset\n",
    "mean = np.mean(X, axis=0)\n",
    "mean1 = np.mean(x_test,axis=0)\n",
    "\n",
    "X = X - mean\n",
    "x_test=x_test-mean1\n",
    "\n",
    "# Compute covariance matrix\n",
    "# print(X_012.T.shape)\n",
    "cov_matrix = np.cov(X, rowvar=False)\n",
    "\n",
    "cov_matrix1=np.cov(x_test,rowvar=False)\n",
    "\n",
    "# cov_matrix = np.cov(X_012.T)\n",
    "# print(cov_matrix.shape)\n",
    "\n",
    "# Computing eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "eigenvalues1, eigenvectors1 = np.linalg.eig(cov_matrix1)\n",
    "\n",
    "\n",
    "# Sorting eigenvectors based on eigenvalues\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "\n",
    "sorted_indices1 = np.argsort(eigenvalues1)[::-1]\n",
    "eigenvectors_sorted1 = eigenvectors1[:, sorted_indices1]\n",
    "\n",
    "\n",
    "# Select the top p eigenvectors\n",
    "p = 10\n",
    "pca_matrix = eigenvectors_sorted[:, :p]\n",
    "print(pca_matrix.shape)\n",
    "\n",
    "\n",
    "pca_matrix1 = eigenvectors_sorted1[:, :p]\n",
    "print(pca_matrix1.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Project the data on reduced dimensional space\n",
    "X_reduced = np.dot(X, pca_matrix)\n",
    "\n",
    "X_reduced1 = np.dot(x_test, pca_matrix1)\n",
    "\n",
    "\n",
    "print(X_reduced.shape)\n",
    "print(X_reduced[0])\n",
    "print(y_train.shape)\n",
    "print(\"Dimensions:\", X_reduced.shape)\n",
    "print(X_reduced1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    # Constructor\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        self.value = value\n",
    "        self.threshold = threshold\n",
    "        self.feature_index = feature_index\n",
    "        \n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    # Constructor\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "    # Function to build a tree\n",
    "    def build_tree(self, dataset, curr_depth=0):    \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # Conditions\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # fOR checking information is positive or not\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "         \n",
    "        # Storing best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = []\n",
    "        dataset_right = []\n",
    "        \n",
    "        for row in dataset:\n",
    "            if row[feature_index] <= threshold:\n",
    "                dataset_left.append(row)\n",
    "            else:\n",
    "                dataset_right.append(row)\n",
    "        \n",
    "        dataset_left = np.array(dataset_left)\n",
    "        dataset_right = np.array(dataset_right)\n",
    "        \n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    \n",
    "    #Finding information gain and then comparing\n",
    "    def information_gain(self, parent, l_child, r_child):        \n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    #Visualizing the tree\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18623, 10)\n",
      "(18623, 1)\n",
      "X_0 <= (624.6639084076752+0j) ? 0.2983877586057319\n",
      " left:X_1 <= (179.67561986817168+0j) ? 0.3037225165600382\n",
      "  left:X_0 <= (-202.45652113485986+0j) ? 0.14759057627204\n",
      "    left:0j\n",
      "    right:(2+0j)\n",
      "  right:X_4 <= (-720.9898876115241+0j) ? 0.0891037058316576\n",
      "    left:0j\n",
      "    right:(2+0j)\n",
      " right:X_2 <= (231.62107754431915+0j) ? 0.06740047510098737\n",
      "  left:X_7 <= (-575.7336812339543+0j) ? 0.0056004210280101545\n",
      "    left:(2+0j)\n",
      "    right:(1+0j)\n",
      "  right:X_1 <= (-480.64812928740986+0j) ? 0.2659279778393353\n",
      "    left:(1+0j)\n",
      "    right:(2+0j)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(X_reduced.shape)\n",
    "y_train=y_train.reshape(-1,1)\n",
    "print(y_train.shape)\n",
    "\n",
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "dataset = np.concatenate((X_reduced[:1000],y_train[:1000]), axis=1)\n",
    "classifier.root = classifier.build_tree(dataset)\n",
    "# classifier.fit()\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6619002224340642"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(np.real(X_reduced1[:10]))\n",
    "# print(y_test)\n",
    "\n",
    "Y_pred = [classifier.make_prediction(x, classifier.root) for x in np.real(X_reduced1)]\n",
    "# Y_pred = classifier.predict(np.real(X_reduced1)) \n",
    "# print(Y_pred)\n",
    "# print(X_reduced1.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, np.real(Y_pred))\n",
    "# Y_pred = np.array(Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.32857142857142857\n",
      "Accuracy for class 1: 0.9145374449339208\n",
      "Accuracy for class 2: 0.7005813953488372\n"
     ]
    }
   ],
   "source": [
    "predictions, labels=np.array(Y_pred), np.array(y_test)\n",
    "unique_classes = np.unique(labels)\n",
    "class_wise_accuracy = {}\n",
    "for class_val in unique_classes:\n",
    "    class_indices = np.where(labels == class_val)[0]\n",
    "    class_accuracy = np.sum(predictions[class_indices] == labels[class_indices]) / len(class_indices)\n",
    "    class_wise_accuracy[class_val] = class_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# class_wise_accuracy = calculate_class_wise_accuracy()\n",
    "\n",
    "\n",
    "for class_val, accuracy in class_wise_accuracy.items():\n",
    "    print(f\"Accuracy for class {class_val}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.+0.j 2.+0.j 2.+0.j 2.+0.j 2.+0.j]\n",
      " [1.+0.j 1.+0.j 1.+0.j 1.+0.j 1.+0.j]\n",
      " [0.+0.j 0.+0.j 2.+0.j 0.+0.j 2.+0.j]\n",
      " ...\n",
      " [0.+0.j 0.+0.j 2.+0.j 0.+0.j 2.+0.j]\n",
      " [1.+0.j 1.+0.j 1.+0.j 1.+0.j 1.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 1.+0.j 0.+0.j]]\n",
      "Total Accuracy: 0.6139180171591992\n",
      "Class-wise Accuracy: {0: 0.6571428571428571, 1: 0.9409691629955947, 2: 0.2131782945736434}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_voting(trees, X_test):\n",
    "    predictions = []\n",
    "    for tree in trees:\n",
    "        prediction = []\n",
    "        for x in X_test:\n",
    "            pred = tree.make_prediction(x, tree.root)\n",
    "            prediction.append(pred)\n",
    "        predictions.append(prediction)\n",
    "    majority_votes = np.array(predictions)\n",
    "    majority_votes = np.swapaxes(majority_votes, 0, 1)\n",
    "    final_predictions = []\n",
    "    print(majority_votes)\n",
    "    for votes in majority_votes:\n",
    "        \n",
    "        vote_count = Counter(votes)\n",
    "        final_predictions.append(vote_count.most_common(1)[0][0])\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "X_train, y_train = X_reduced[:1000], y_train[:1000]\n",
    "datasets = []\n",
    "for _ in range(5):\n",
    "    indices = np.random.choice(len(X_train), 100, replace=True)\n",
    "    X_sample,y_sample = X_train[indices], y_train[indices]\n",
    "    datasets.append((X_sample, y_sample))\n",
    "\n",
    "\n",
    "trees = []\n",
    "for X_sample, y_sample in datasets:\n",
    "    tree = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "    dataset = np.concatenate((X_sample, y_sample), axis=1)\n",
    "    tree.root = tree.build_tree(dataset)\n",
    "    trees.append(tree)\n",
    "\n",
    "predictions = majority_voting(trees, X_reduced1)\n",
    "\n",
    "total_accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "class_accuracy = {}\n",
    "for class_label in np.unique(y_test):\n",
    "    correct = np.sum((predictions == y_test) & (y_test == class_label))\n",
    "    total = np.sum(y_test == class_label)\n",
    "    class_accuracy[class_label] = correct / total\n",
    "\n",
    "print(\"Total Accuracy:\", total_accuracy)\n",
    "print(\"Class-wise Accuracy:\", class_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
